---
output: word_document
---
```{r}
# Now we can model the data
#loadrequiredlibrariesforpreprocessing(TRUE)
setwd('/Users/dsing001/LV/R')
library(ggplot2)
library(discretization)
library(randomForest)
library(ROCR)
library(LV)
library(unbalanced)

clscol='Class'

# read the data which we saved as part of part 2 aka feature selection
train_data <- read.csv('fs_train_data.csv')
test_data <- read.csv('fs_test_data.csv')
valid_data <- read.csv('fs_validdata.csv')

#Now add the interaction terms
# from decision tree

frml1 <- 'Class ~ . + Loan.Purpose:Loan.Term + Loan.Purpose:Loan.Amount + Loan.Purpose:No..Delinquencies.In.Last.2.Years + Loan.Purpose:Use.Of.Credit.Line'

md_prms <- train_and_predict_log_reg_and_ret_auc(frml1,train_data,valid_data,predict_type='response')
auc <- md_prms$auc
mdl <- md_prms$model
tst_with_prob <- md_prms$tst_with_prob
#
AUC <- auc$AUC
GC <- (2*AUC) - 1
KS <- auc$KS
KSRealized <- auc$KSRealized
AUC
GC
KS
rocperf <- auc$rocperf


plot(rocperf,col='blue',xlim = c(0,1), ylim = c(0,1)) 
cutoffvalues <- as.vector(attr(rocperf,'alpha.values')[[1]])
cutoffvalue <- cutoffvalues[KSRealized]
cutoffvalue
#generate the confusion matrix. To get the cutoff I will use the fact that we have KS score. Thus, where we have that value occuring we will have the best accuracy/recall/precision
tst_with_prob$predclass <- ifelse(tst_with_prob$predprob>cutoffvalue,1,0)
ab <- table(tst_with_prob$predclass,tst_with_prob$Class)
ab
recall <- ab[2,2]/(ab[1,2] + ab[2,2])
recall

#
#> AUC
#[1] 0.7171746
#> GC
#[1] 0.4343492
#> KS
#[1] 0.3388137

# first 5 terms form interaction logistic for pair

##136               No..Of.Credit.Lines                Use.Of.Credit.Line
## 143        No..Adverse.Public.Records      Loan.Application.Description
## 139               No..Of.Credit.Lines No..Of.Public.Record.Bankruptcies
## 33                          Loan.Term      Loan.Application.Description
## 62                     Home.Ownership      Loan.Application.Description
## 106       Earliest.Credit.Line.Opened                Use.Of.Credit.Line


frml1 <- 'Class ~ . + No..Of.Credit.Lines:Use.Of.Credit.Line + No..Adverse.Public.Records:Loan.Application.Description
+ No..Of.Credit.Lines:No..Of.Public.Record.Bankruptcies + Loan.Term:Loan.Application.Description + Home.Ownership:Loan.Application.Description + Earliest.Credit.Line.Opened:Use.Of.Credit.Line'

md_prms <- train_and_predict_log_reg_and_ret_auc(frml1,train_data,valid_data,predict_type='response')
auc <- md_prms$auc
mdl <- md_prms$model
# This is just the test data along with predicted probabilty value.
tst_with_prob <- md_prms$tst_with_prob
#
AUC <- auc$AUC
GC <- (2*AUC) - 1
KS <- auc$KS
KSRealized <- auc$KSRealized
AUC
GC
KS
rocperf <- auc$rocperf

plot(rocperf,col='blue',xlim = c(0,1), ylim = c(0,1)) 
cutoffvalues <- as.vector(attr(rocperf,'alpha.values')[[1]])
cutoffvalue <- cutoffvalues[KSRealized]
cutoffvalue
#generate the confusion matrix. To get the cutoff I will use the fact that we have KS score. Thus, where we have that value occuring we will have the best accuracy/recall/precision
tst_with_prob$predclass <- ifelse(tst_with_prob$predprob>cutoffvalue,1,0)
ab <- table(tst_with_prob$predclass,tst_with_prob$Class)
ab
recall <- ab[2,2]/(ab[1,2] + ab[2,2])
recall

#> AUC
#[1] 0.7183425
#> GC
#[1] 0.4366851
#> KS
#[1] 0.3326968

# Simialrly we canremove th ecolumns which are not important as per chi square or as per the logical model we ran for single columns or based on the ranking in random forest

#Also, we can add the interatcion terms based on the random forest generated. I have not tried these but I could try later.

```


```
